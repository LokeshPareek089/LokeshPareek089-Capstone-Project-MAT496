{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c041d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Environment loaded\n",
      "‚úì GROQ_API_KEY: Set\n",
      "‚úì TAVILY_API_KEY: Set\n",
      "‚úì LANGSMITH_API_KEY: Set\n",
      "‚úì LANGSMITH_TRACING: true\n",
      "‚úì LANGSMITH_PROJECT: pr-overcooked-baggage-31\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Annotated, Optional\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from tavily import TavilyClient\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API keys and config are loaded\n",
    "print(\"‚úì Environment loaded\")\n",
    "print(f\"‚úì GROQ_API_KEY: {'Set' if os.getenv('GROQ_API_KEY') else 'NOT SET'}\")\n",
    "print(f\"‚úì TAVILY_API_KEY: {'Set' if os.getenv('TAVILY_API_KEY') else 'NOT SET'}\")\n",
    "print(f\"‚úì LANGSMITH_API_KEY: {'Set' if os.getenv('LANGSMITH_API_KEY') else 'NOT SET'}\")\n",
    "print(f\"‚úì LANGSMITH_TRACING: {os.getenv('LANGSMITH_TRACING')}\")\n",
    "print(f\"‚úì LANGSMITH_PROJECT: {os.getenv('LANGSMITH_PROJECT')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17add8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Pydantic models defined\n"
     ]
    }
   ],
   "source": [
    "# Pydantic models for structured outputs\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    \"\"\"Neutral summary of the article\"\"\"\n",
    "    summary: str = Field(description=\"A short, neutral summary of the article (2-3 sentences)\")\n",
    "    word_count: int = Field(description=\"Approximate word count of original article\")\n",
    "\n",
    "class Claim(BaseModel):\n",
    "    \"\"\"Individual claim or statement\"\"\"\n",
    "    text: str = Field(description=\"The claim or statement\")\n",
    "    type: str = Field(description=\"Either 'fact' or 'opinion'\")\n",
    "    confidence: float = Field(description=\"Confidence in classification (0-1)\")\n",
    "\n",
    "class ClaimsExtraction(BaseModel):\n",
    "    \"\"\"Extracted claims from article\"\"\"\n",
    "    factual_claims: List[Claim] = Field(description=\"List of factual claims\")\n",
    "    opinions: List[Claim] = Field(description=\"List of opinions\")\n",
    "    total_claims: int = Field(description=\"Total number of claims extracted\")\n",
    "\n",
    "class FactCheck(BaseModel):\n",
    "    \"\"\"Fact check result for a claim\"\"\"\n",
    "    claim: str = Field(description=\"The original claim\")\n",
    "    status: str = Field(description=\"Either 'supported', 'contradicted', or 'unclear'\")\n",
    "    evidence: str = Field(description=\"Summary of evidence found\")\n",
    "    sources: List[str] = Field(description=\"URLs of sources\")\n",
    "    confidence: float = Field(description=\"Confidence in fact check (0-1)\")\n",
    "\n",
    "class FactCheckResults(BaseModel):\n",
    "    \"\"\"All fact check results\"\"\"\n",
    "    checks: List[FactCheck] = Field(description=\"List of fact check results\")\n",
    "    needs_review: bool = Field(description=\"Whether human review is needed\")\n",
    "\n",
    "class LanguageAnalysis(BaseModel):\n",
    "    \"\"\"Analysis of language bias\"\"\"\n",
    "    loaded_phrases: List[str] = Field(description=\"Emotionally loaded or biased phrases\")\n",
    "    tone: str = Field(description=\"Overall tone: neutral, positive, negative, inflammatory\")\n",
    "    language_bias_score: float = Field(description=\"Language bias score (0-1, 0=neutral)\")\n",
    "    examples: List[str] = Field(description=\"Example sentences showing bias\")\n",
    "\n",
    "class BiasReport(BaseModel):\n",
    "    \"\"\"Final bias analysis report\"\"\"\n",
    "    bias_score: float = Field(description=\"Overall bias score (0-1, 0=unbiased)\")\n",
    "    stance: str = Field(description=\"Predicted stance or position\")\n",
    "    confidence: float = Field(description=\"Confidence in assessment (0-1)\")\n",
    "    key_factors: List[str] = Field(description=\"Key factors contributing to bias score\")\n",
    "    recommendation: str = Field(description=\"Recommendation for readers\")\n",
    "\n",
    "print(\"‚úì Pydantic models defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54724dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì State schema defined\n"
     ]
    }
   ],
   "source": [
    "# LangGraph State\n",
    "class BiasDetectorState(TypedDict):\n",
    "    # Input\n",
    "    article_text: str\n",
    "    article_url: Optional[str]\n",
    "    \n",
    "    # Processing stages\n",
    "    summary: Optional[Summary]\n",
    "    claims: Optional[ClaimsExtraction]\n",
    "    fact_checks: Optional[FactCheckResults]\n",
    "    language_analysis: Optional[LanguageAnalysis]\n",
    "    bias_report: Optional[BiasReport]\n",
    "    \n",
    "    # Control flow\n",
    "    needs_human_review: bool\n",
    "    review_reason: Optional[str]\n",
    "    human_approved: bool\n",
    "    \n",
    "    # Messages for tracing\n",
    "    messages: List[str]\n",
    "\n",
    "print(\"‚úì State schema defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dae8002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì LLM initialized (Groq - llama-3.3-70b-versatile)\n",
      "‚úì Tavily client initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM with structured output support\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.1,\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")\n",
    "\n",
    "# Initialize Tavily client for web search\n",
    "tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "\n",
    "print(\"‚úì LLM initialized (Groq - llama-3.3-70b-versatile)\")\n",
    "print(\"‚úì Tavily client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf43c878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Article fetcher defined\n"
     ]
    }
   ],
   "source": [
    "def fetch_article_from_url(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetch article text from a URL using web scraping.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Remove script and style elements\n",
    "        for script in soup([\"script\", \"style\", \"nav\", \"header\", \"footer\"]):\n",
    "            script.decompose()\n",
    "        \n",
    "        # Get text from paragraphs\n",
    "        paragraphs = soup.find_all('p')\n",
    "        article_text = '\\n\\n'.join([p.get_text().strip() for p in paragraphs if p.get_text().strip()])\n",
    "        \n",
    "        if len(article_text) < 100:\n",
    "            # Fallback to all text\n",
    "            article_text = soup.get_text(separator='\\n', strip=True)\n",
    "        \n",
    "        return article_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error fetching article: {str(e)}\"\n",
    "\n",
    "print(\"‚úì Article fetcher defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "105cfcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Summarization node defined\n"
     ]
    }
   ],
   "source": [
    "def summarize_node(state: BiasDetectorState) -> BiasDetectorState:\n",
    "    \"\"\"\n",
    "    Generate a neutral summary of the article.\n",
    "    \"\"\"\n",
    "    print(\"\\nüîÑ Running: Summarization Node\")\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(Summary)\n",
    "    \n",
    "    prompt = f\"\"\"You are a neutral news analyst. Read the following article and provide a short, neutral summary.\n",
    "Focus on the main facts and events without adding interpretation or opinion.\n",
    "\n",
    "Article:\n",
    "{state['article_text'][:3000]}  # Limit for context\n",
    "\n",
    "Provide a 2-3 sentence neutral summary and estimate the word count.\"\"\"\n",
    "\n",
    "    summary = structured_llm.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    state['summary'] = summary\n",
    "    state['messages'].append(f\"Summary created: {len(summary.summary)} chars\")\n",
    "    \n",
    "    print(f\"‚úì Summary: {summary.summary[:100]}...\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"‚úì Summarization node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17763520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Claims extraction node defined\n"
     ]
    }
   ],
   "source": [
    "def extract_claims_node(state: BiasDetectorState) -> BiasDetectorState:\n",
    "    \"\"\"\n",
    "    Extract factual claims and opinions from the article.\n",
    "    \"\"\"\n",
    "    print(\"\\nüîÑ Running: Claims Extraction Node\")\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(ClaimsExtraction)\n",
    "    \n",
    "    prompt = f\"\"\"You are a critical analyst. Read this article and extract key claims.\n",
    "\n",
    "Separate them into:\n",
    "1. FACTUAL CLAIMS: Statements that can be verified (dates, events, statistics, quotes)\n",
    "2. OPINIONS: Judgments, interpretations, predictions, or subjective statements\n",
    "\n",
    "Article:\n",
    "{state['article_text'][:4000]}\n",
    "\n",
    "For each claim, provide:\n",
    "- The exact text of the claim\n",
    "- Type: 'fact' or 'opinion'\n",
    "- Confidence: How confident you are in the classification (0-1)\n",
    "\n",
    "Extract 5-10 of the most important claims.\"\"\"\n",
    "\n",
    "    claims = structured_llm.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    state['claims'] = claims\n",
    "    state['messages'].append(f\"Extracted {claims.total_claims} claims: {len(claims.factual_claims)} facts, {len(claims.opinions)} opinions\")\n",
    "    \n",
    "    print(f\"‚úì Extracted {len(claims.factual_claims)} factual claims\")\n",
    "    print(f\"‚úì Extracted {len(claims.opinions)} opinions\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"‚úì Claims extraction node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b388cdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Fact checking node defined\n"
     ]
    }
   ],
   "source": [
    "def fact_check_node(state: BiasDetectorState) -> BiasDetectorState:\n",
    "    \"\"\"\n",
    "    Fact-check claims using Tavily web search.\n",
    "    \"\"\"\n",
    "    print(\"\\nüîÑ Running: Fact Checking Node\")\n",
    "    \n",
    "    claims = state['claims']\n",
    "    fact_checks = []\n",
    "    needs_review = False\n",
    "    \n",
    "    # Select top 3-5 most important factual claims\n",
    "    factual_claims = claims.factual_claims[:5]\n",
    "    \n",
    "    for claim_obj in factual_claims:\n",
    "        claim_text = claim_obj.text\n",
    "        print(f\"  üîç Checking: {claim_text[:60]}...\")\n",
    "        \n",
    "        try:\n",
    "            # Search for information about the claim\n",
    "            search_results = tavily_client.search(\n",
    "                query=claim_text,\n",
    "                max_results=3\n",
    "            )\n",
    "            \n",
    "            # Analyze results with LLM\n",
    "            context = \"\\n\\n\".join([\n",
    "                f\"Source: {r.get('url', 'Unknown')}\\n{r.get('content', '')}\" \n",
    "                for r in search_results.get('results', [])\n",
    "            ])\n",
    "            \n",
    "            analysis_prompt = f\"\"\"Based on the following web search results, determine if this claim is supported, contradicted, or unclear.\n",
    "\n",
    "Claim: {claim_text}\n",
    "\n",
    "Search Results:\n",
    "{context[:2000]}\n",
    "\n",
    "Determine:\n",
    "1. Status: 'supported', 'contradicted', or 'unclear'\n",
    "2. Brief evidence summary\n",
    "3. Confidence (0-1)\n",
    "\n",
    "Be conservative: if evidence is mixed or insufficient, mark as 'unclear'.\"\"\"\n",
    "\n",
    "            response = llm.invoke([HumanMessage(content=analysis_prompt)])\n",
    "            \n",
    "            # Parse response\n",
    "            status = \"unclear\"\n",
    "            if \"supported\" in response.content.lower():\n",
    "                status = \"supported\"\n",
    "            elif \"contradicted\" in response.content.lower():\n",
    "                status = \"contradicted\"\n",
    "            \n",
    "            # Extract confidence\n",
    "            confidence = 0.5\n",
    "            if \"high confidence\" in response.content.lower() or \"clearly\" in response.content.lower():\n",
    "                confidence = 0.8\n",
    "            elif \"unclear\" in status or \"insufficient\" in response.content.lower():\n",
    "                confidence = 0.3\n",
    "                needs_review = True\n",
    "            \n",
    "            fact_check = FactCheck(\n",
    "                claim=claim_text,\n",
    "                status=status,\n",
    "                evidence=response.content[:300],\n",
    "                sources=[r.get('url', '') for r in search_results.get('results', [])[:3]],\n",
    "                confidence=confidence\n",
    "            )\n",
    "            \n",
    "            fact_checks.append(fact_check)\n",
    "            print(f\"    ‚úì Status: {status} (confidence: {confidence:.2f})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    ‚úó Error: {str(e)}\")\n",
    "            fact_checks.append(FactCheck(\n",
    "                claim=claim_text,\n",
    "                status=\"unclear\",\n",
    "                evidence=f\"Error during fact check: {str(e)}\",\n",
    "                sources=[],\n",
    "                confidence=0.0\n",
    "            ))\n",
    "            needs_review = True\n",
    "    \n",
    "    state['fact_checks'] = FactCheckResults(\n",
    "        checks=fact_checks,\n",
    "        needs_review=needs_review\n",
    "    )\n",
    "    state['needs_human_review'] = needs_review\n",
    "    if needs_review:\n",
    "        state['review_reason'] = \"Low confidence in fact checking results\"\n",
    "    \n",
    "    state['messages'].append(f\"Fact-checked {len(fact_checks)} claims\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"‚úì Fact checking node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "829158ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Language analysis node defined\n"
     ]
    }
   ],
   "source": [
    "def language_analysis_node(state: BiasDetectorState) -> BiasDetectorState:\n",
    "    \"\"\"\n",
    "    Analyze language for emotional or loaded wording.\n",
    "    \"\"\"\n",
    "    print(\"\\nüîÑ Running: Language Analysis Node\")\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(LanguageAnalysis)\n",
    "    \n",
    "    prompt = f\"\"\"You are a linguistic analyst. Analyze this article for biased or emotionally loaded language.\n",
    "\n",
    "Look for:\n",
    "- Emotionally charged words (e.g., \"catastrophic\", \"hero\", \"villain\")\n",
    "- Loaded adjectives and adverbs\n",
    "- One-sided framing\n",
    "- Inflammatory rhetoric\n",
    "- Persuasive language\n",
    "\n",
    "Article excerpt:\n",
    "{state['article_text'][:4000]}\n",
    "\n",
    "Provide:\n",
    "1. List of loaded phrases (with context)\n",
    "2. Overall tone: neutral, positive, negative, or inflammatory\n",
    "3. Language bias score (0 = perfectly neutral, 1 = extremely biased)\n",
    "4. Example sentences showing bias\"\"\"\n",
    "\n",
    "    analysis = structured_llm.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    state['language_analysis'] = analysis\n",
    "    state['messages'].append(f\"Language analysis: tone={analysis.tone}, bias={analysis.language_bias_score:.2f}\")\n",
    "    \n",
    "    print(f\"‚úì Tone: {analysis.tone}\")\n",
    "    print(f\"‚úì Language bias score: {analysis.language_bias_score:.2f}\")\n",
    "    print(f\"‚úì Found {len(analysis.loaded_phrases)} loaded phrases\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"‚úì Language analysis node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a578ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Bias scoring node defined\n"
     ]
    }
   ],
   "source": [
    "def bias_scoring_node(state: BiasDetectorState) -> BiasDetectorState:\n",
    "    \"\"\"\n",
    "    Calculate final bias score and predict stance.\n",
    "    \"\"\"\n",
    "    print(\"\\nüîÑ Running: Bias Scoring Node\")\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(BiasReport)\n",
    "    \n",
    "    # Compile all analysis\n",
    "    summary_text = state['summary'].summary if state['summary'] else \"No summary\"\n",
    "    \n",
    "    fact_summary = \"\\n\".join([\n",
    "        f\"- {fc.claim}: {fc.status} (conf: {fc.confidence:.2f})\"\n",
    "        for fc in state['fact_checks'].checks\n",
    "    ]) if state['fact_checks'] else \"No fact checks\"\n",
    "    \n",
    "    lang_summary = f\"Tone: {state['language_analysis'].tone}, Score: {state['language_analysis'].language_bias_score}\" if state['language_analysis'] else \"No analysis\"\n",
    "    \n",
    "    prompt = f\"\"\"You are a media bias expert. Based on all the analysis, provide a final bias assessment.\n",
    "\n",
    "SUMMARY:\n",
    "{summary_text}\n",
    "\n",
    "FACT CHECK RESULTS:\n",
    "{fact_summary}\n",
    "\n",
    "LANGUAGE ANALYSIS:\n",
    "{lang_summary}\n",
    "Loaded phrases: {', '.join(state['language_analysis'].loaded_phrases[:5]) if state['language_analysis'] else 'None'}\n",
    "\n",
    "Calculate:\n",
    "1. Overall bias score (0-1):\n",
    "   - 0.0-0.2: Minimal bias\n",
    "   - 0.2-0.4: Low bias\n",
    "   - 0.4-0.6: Moderate bias\n",
    "   - 0.6-0.8: High bias\n",
    "   - 0.8-1.0: Extreme bias\n",
    "\n",
    "2. Predicted stance (e.g., \"pro-government\", \"anti-corporate\", \"left-leaning\", \"right-leaning\", \"neutral\")\n",
    "\n",
    "3. Confidence in your assessment (0-1)\n",
    "\n",
    "4. Key factors contributing to the score\n",
    "\n",
    "5. Recommendation for readers\n",
    "\n",
    "Consider:\n",
    "- Contradicted facts increase bias\n",
    "- Emotional language increases bias\n",
    "- One-sided coverage increases bias\n",
    "- Missing context increases bias\"\"\"\n",
    "\n",
    "    report = structured_llm.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    state['bias_report'] = report\n",
    "    state['messages'].append(f\"Final bias score: {report.bias_score:.2f}, stance: {report.stance}\")\n",
    "    \n",
    "    # Check if we need review due to high bias or low confidence\n",
    "    if report.bias_score > 0.7 or report.confidence < 0.5:\n",
    "        state['needs_human_review'] = True\n",
    "        state['review_reason'] = f\"High bias score ({report.bias_score:.2f}) or low confidence ({report.confidence:.2f})\"\n",
    "    \n",
    "    print(f\"‚úì Bias score: {report.bias_score:.2f}\")\n",
    "    print(f\"‚úì Stance: {report.stance}\")\n",
    "    print(f\"‚úì Confidence: {report.confidence:.2f}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"‚úì Bias scoring node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce57c3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Human review node defined\n"
     ]
    }
   ],
   "source": [
    "def human_review_node(state: BiasDetectorState) -> BiasDetectorState:\n",
    "    \"\"\"\n",
    "    Pause for human review if needed.\n",
    "    \"\"\"\n",
    "    print(\"\\n‚ö†Ô∏è  HUMAN REVIEW REQUIRED\")\n",
    "    print(f\"Reason: {state.get('review_reason', 'Unknown')}\")\n",
    "    print(\"\\nCurrent Analysis:\")\n",
    "    print(f\"- Bias Score: {state['bias_report'].bias_score:.2f}\")\n",
    "    print(f\"- Stance: {state['bias_report'].stance}\")\n",
    "    print(f\"- Confidence: {state['bias_report'].confidence:.2f}\")\n",
    "    \n",
    "    if state['fact_checks']:\n",
    "        print(f\"\\nFact Checks:\")\n",
    "        for fc in state['fact_checks'].checks:\n",
    "            print(f\"  - {fc.claim[:60]}... ‚Üí {fc.status}\")\n",
    "    \n",
    "    # In notebook, this will pause execution\n",
    "    # User can inspect state and decide to continue\n",
    "    print(\"\\n‚úì Review node reached (set state['human_approved'] = True to continue)\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"‚úì Human review node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33cd1a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Routing functions defined\n"
     ]
    }
   ],
   "source": [
    "def should_review(state: BiasDetectorState) -> str:\n",
    "    \"\"\"\n",
    "    Decide whether to route to human review or final output.\n",
    "    \"\"\"\n",
    "    if state.get('needs_human_review', False) and not state.get('human_approved', False):\n",
    "        return \"review\"\n",
    "    return \"end\"\n",
    "\n",
    "print(\"‚úì Routing functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7540668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì LangGraph workflow compiled\n",
      "‚úì Checkpointer enabled with interrupt before human_review\n"
     ]
    }
   ],
   "source": [
    "# Build the LangGraph workflow\n",
    "workflow = StateGraph(BiasDetectorState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"summarize\", summarize_node)\n",
    "workflow.add_node(\"extract_claims\", extract_claims_node)\n",
    "workflow.add_node(\"fact_check\", fact_check_node)\n",
    "workflow.add_node(\"language_analysis\", language_analysis_node)\n",
    "workflow.add_node(\"bias_scoring\", bias_scoring_node)\n",
    "workflow.add_node(\"human_review\", human_review_node)\n",
    "\n",
    "# Define edges\n",
    "workflow.set_entry_point(\"summarize\")\n",
    "workflow.add_edge(\"summarize\", \"extract_claims\")\n",
    "workflow.add_edge(\"extract_claims\", \"fact_check\")\n",
    "workflow.add_edge(\"fact_check\", \"language_analysis\")\n",
    "workflow.add_edge(\"language_analysis\", \"bias_scoring\")\n",
    "\n",
    "# Conditional edge for human review\n",
    "workflow.add_conditional_edges(\n",
    "    \"bias_scoring\",\n",
    "    should_review,\n",
    "    {\n",
    "        \"review\": \"human_review\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"human_review\", END)\n",
    "\n",
    "# Compile with checkpointer for breakpoints\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory, interrupt_before=[\"human_review\"])\n",
    "\n",
    "print(\"‚úì LangGraph workflow compiled\")\n",
    "print(\"‚úì Checkpointer enabled with interrupt before human_review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da67e1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Display function defined\n"
     ]
    }
   ],
   "source": [
    "def display_results(state: BiasDetectorState):\n",
    "    \"\"\"\n",
    "    Pretty print the analysis results.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üì∞ NEWS BIAS DETECTION REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if state.get('article_url'):\n",
    "        print(f\"\\nüîó Source URL: {state['article_url']}\")\n",
    "    \n",
    "    # Summary\n",
    "    if state.get('summary'):\n",
    "        print(f\"\\nüìù SUMMARY:\")\n",
    "        print(f\"{state['summary'].summary}\")\n",
    "        print(f\"Word count: ~{state['summary'].word_count}\")\n",
    "    \n",
    "    # Claims\n",
    "    if state.get('claims'):\n",
    "        print(f\"\\nüìä CLAIMS EXTRACTED:\")\n",
    "        print(f\"  Factual claims: {len(state['claims'].factual_claims)}\")\n",
    "        print(f\"  Opinions: {len(state['claims'].opinions)}\")\n",
    "        \n",
    "        print(\"\\n  Top Factual Claims:\")\n",
    "        for i, claim in enumerate(state['claims'].factual_claims[:3], 1):\n",
    "            print(f\"    {i}. {claim.text}\")\n",
    "        \n",
    "        print(\"\\n  Top Opinions:\")\n",
    "        for i, opinion in enumerate(state['claims'].opinions[:3], 1):\n",
    "            print(f\"    {i}. {opinion.text}\")\n",
    "    \n",
    "    # Fact Checks\n",
    "    if state.get('fact_checks'):\n",
    "        print(f\"\\nüîç FACT CHECK RESULTS:\")\n",
    "        for fc in state['fact_checks'].checks:\n",
    "            print(f\"\\n  Claim: {fc.claim}\")\n",
    "            print(f\"  Status: {fc.status.upper()}\")\n",
    "            print(f\"  Confidence: {fc.confidence:.2f}\")\n",
    "            if fc.sources:\n",
    "                print(f\"  Sources: {fc.sources[0]}\")\n",
    "    \n",
    "    # Language Analysis\n",
    "    if state.get('language_analysis'):\n",
    "        lang = state['language_analysis']\n",
    "        print(f\"\\nüí¨ LANGUAGE ANALYSIS:\")\n",
    "        print(f\"  Tone: {lang.tone}\")\n",
    "        print(f\"  Language Bias Score: {lang.language_bias_score:.2f}\")\n",
    "        print(f\"  Loaded Phrases: {len(lang.loaded_phrases)}\")\n",
    "        if lang.loaded_phrases:\n",
    "            print(f\"    Examples: {', '.join(lang.loaded_phrases[:3])}\")\n",
    "    \n",
    "    # Final Report\n",
    "    if state.get('bias_report'):\n",
    "        report = state['bias_report']\n",
    "        print(f\"\\n‚öñÔ∏è  FINAL BIAS ASSESSMENT:\")\n",
    "        print(f\"  Bias Score: {report.bias_score:.2f} / 1.0\")\n",
    "        print(f\"  Stance: {report.stance}\")\n",
    "        print(f\"  Confidence: {report.confidence:.2f}\")\n",
    "        \n",
    "        print(f\"\\n  Key Factors:\")\n",
    "        for factor in report.key_factors:\n",
    "            print(f\"    ‚Ä¢ {factor}\")\n",
    "        \n",
    "        print(f\"\\n  üí° Recommendation:\")\n",
    "        print(f\"  {report.recommendation}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "print(\"‚úì Display function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28a15ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Main execution functions defined\n"
     ]
    }
   ],
   "source": [
    "def analyze_news(article_text: str = None, article_url: str = None, thread_id: str = \"1\"):\n",
    "    \"\"\"\n",
    "    Main function to analyze a news article.\n",
    "    \n",
    "    Args:\n",
    "        article_text: Direct article text (optional)\n",
    "        article_url: URL to fetch article from (optional)\n",
    "        thread_id: Thread ID for checkpointing\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fetch article if URL provided\n",
    "    if article_url and not article_text:\n",
    "        print(f\"üì• Fetching article from: {article_url}\")\n",
    "        article_text = fetch_article_from_url(article_url)\n",
    "        \n",
    "        if article_text.startswith(\"Error\"):\n",
    "            print(f\"‚ùå {article_text}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"‚úì Fetched {len(article_text)} characters\")\n",
    "    \n",
    "    if not article_text:\n",
    "        print(\"‚ùå No article text provided\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize state\n",
    "    initial_state = {\n",
    "        \"article_text\": article_text,\n",
    "        \"article_url\": article_url,\n",
    "        \"summary\": None,\n",
    "        \"claims\": None,\n",
    "        \"fact_checks\": None,\n",
    "        \"language_analysis\": None,\n",
    "        \"bias_report\": None,\n",
    "        \"needs_human_review\": False,\n",
    "        \"review_reason\": None,\n",
    "        \"human_approved\": False,\n",
    "        \"messages\": []\n",
    "    }\n",
    "    \n",
    "    # Run the workflow\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    print(\"\\nüöÄ Starting bias detection analysis...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    final_state = None\n",
    "    \n",
    "    for state in app.stream(initial_state, config):\n",
    "        final_state = list(state.values())[0]\n",
    "        \n",
    "        # Check if we hit a breakpoint\n",
    "        if final_state.get('needs_human_review') and not final_state.get('human_approved'):\n",
    "            print(\"\\n‚è∏Ô∏è  Analysis paused at breakpoint\")\n",
    "            print(\"Review the results and run continue_analysis() to proceed\")\n",
    "            return final_state\n",
    "    \n",
    "    # Display results\n",
    "    display_results(final_state)\n",
    "    \n",
    "    return final_state\n",
    "\n",
    "def continue_analysis(thread_id: str = \"1\", approved: bool = True):\n",
    "    \"\"\"\n",
    "    Continue analysis after human review.\n",
    "    \"\"\"\n",
    "    print(f\"\\n‚ñ∂Ô∏è  Continuing analysis (approved={approved})...\")\n",
    "    \n",
    "    # Update state to mark as approved\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    # Get current state\n",
    "    current_state = app.get_state(config)\n",
    "    current_values = current_state.values\n",
    "    current_values['human_approved'] = approved\n",
    "    \n",
    "    # Update and continue\n",
    "    app.update_state(config, current_values)\n",
    "    \n",
    "    # Continue execution\n",
    "    for state in app.stream(None, config):\n",
    "        final_state = list(state.values())[0]\n",
    "    \n",
    "    display_results(final_state)\n",
    "    return final_state\n",
    "\n",
    "print(\"‚úì Main execution functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ce490f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting bias detection analysis...\n",
      "================================================================================\n",
      "\n",
      "üîÑ Running: Summarization Node\n",
      "‚úì Summary: MegaCorp has announced it will be laying off 10,000 employees in a cost-cutting measure, citing long...\n",
      "\n",
      "üîÑ Running: Claims Extraction Node\n",
      "‚úì Extracted 5 factual claims\n",
      "‚úì Extracted 3 opinions\n",
      "\n",
      "üîÑ Running: Fact Checking Node\n",
      "  üîç Checking: MegaCorp announced today that it will be slashing 10,000 job...\n",
      "    ‚úì Status: contradicted (confidence: 0.50)\n",
      "  üîç Checking: The company reported record profits of $50 billion last quar...\n",
      "    ‚úì Status: unclear (confidence: 0.30)\n",
      "  üîç Checking: CEO John Smith defended the decision, claiming it was necess...\n",
      "    ‚úì Status: unclear (confidence: 0.30)\n",
      "  üîç Checking: Workers say they received no warning and many learned about ...\n",
      "    ‚úì Status: supported (confidence: 0.50)\n",
      "  üîç Checking: Industry analysts suggest the layoffs are part of a broader ...\n",
      "    ‚úì Status: supported (confidence: 0.50)\n",
      "\n",
      "‚è∏Ô∏è  Analysis paused at breakpoint\n",
      "Review the results and run continue_analysis() to proceed\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Analyze article from direct text\n",
    "\n",
    "sample_article = \"\"\"\n",
    "Breaking: Tech Giant Announces Shocking Layoffs\n",
    "\n",
    "In a devastating blow to workers, MegaCorp announced today that it will be slashing \n",
    "10,000 jobs in what critics are calling a \"ruthless\" cost-cutting measure. The \n",
    "announcement sent shockwaves through the tech industry.\n",
    "\n",
    "CEO John Smith defended the decision, claiming it was necessary for \"long-term \n",
    "sustainability,\" but employees and advocates are outraged. \"This is corporate greed \n",
    "at its finest,\" said Sarah Johnson, a labor organizer.\n",
    "\n",
    "The company reported record profits of $50 billion last quarter, yet is still \n",
    "eliminating positions. Workers say they received no warning and many learned about \n",
    "their termination through email.\n",
    "\n",
    "Industry analysts suggest the layoffs are part of a broader trend, with several \n",
    "major tech companies reducing headcount this year. However, employee advocates \n",
    "argue that profitable companies have no excuse for such drastic measures.\n",
    "\"\"\"\n",
    "\n",
    "# Run analysis\n",
    "result = analyze_news(article_text=sample_article, thread_id=\"example1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "572ad137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Fetching article from: https://www.bbc.com/news/world\n",
      "‚úì Fetched 3436 characters\n",
      "\n",
      "üöÄ Starting bias detection analysis...\n",
      "================================================================================\n",
      "\n",
      "üîÑ Running: Summarization Node\n",
      "‚úì Summary: The death toll on the island of Sumatra has risen to over 440, and multiple other global events have...\n",
      "\n",
      "üîÑ Running: Claims Extraction Node\n",
      "‚úì Extracted 5 factual claims\n",
      "‚úì Extracted 2 opinions\n",
      "\n",
      "üîÑ Running: Fact Checking Node\n",
      "  üîç Checking: The death toll on the island of Sumatra has risen to more th...\n",
      "    ‚úì Status: contradicted (confidence: 0.50)\n",
      "  üîç Checking: At least 80 people have died in Indonesia with another 56 de...\n",
      "    ‚úì Status: supported (confidence: 0.50)\n",
      "  üîç Checking: Dozens have been arrested during climate protests at one of ...\n",
      "    ‚úì Status: supported (confidence: 0.50)\n",
      "  üîç Checking: Police say 10 others are injured in what they believe is a \"...\n",
      "    ‚úì Status: supported (confidence: 0.50)\n",
      "  üîç Checking: A state of emergency is announced as Sri Lanka grapples with...\n",
      "    ‚úì Status: supported (confidence: 0.50)\n",
      "\n",
      "üîÑ Running: Language Analysis Node\n",
      "‚úì Tone: neutral\n",
      "‚úì Language bias score: 0.20\n",
      "‚úì Found 3 loaded phrases\n",
      "\n",
      "üîÑ Running: Bias Scoring Node\n",
      "‚úì Bias score: 0.30\n",
      "‚úì Stance: neutral\n",
      "‚úì Confidence: 0.70\n",
      "\n",
      "================================================================================\n",
      "üì∞ NEWS BIAS DETECTION REPORT\n",
      "================================================================================\n",
      "\n",
      "üîó Source URL: https://www.bbc.com/news/world\n",
      "\n",
      "üìù SUMMARY:\n",
      "The death toll on the island of Sumatra has risen to over 440, and multiple other global events have occurred, including a targeted shooting with children among the victims, climate protests, and a corruption scandal in Ukraine. Various investigations and searches are underway in response to these events. Extreme weather has also caused significant damage and loss of life in Indonesia and Sri Lanka.\n",
      "Word count: ~500\n",
      "\n",
      "üìä CLAIMS EXTRACTED:\n",
      "  Factual claims: 5\n",
      "  Opinions: 2\n",
      "\n",
      "  Top Factual Claims:\n",
      "    1. The death toll on the island of Sumatra has risen to more than 440, the government says.\n",
      "    2. At least 80 people have died in Indonesia with another 56 dead in Sri Lanka in a week of extreme weather.\n",
      "    3. Dozens have been arrested during climate protests at one of the world's biggest coal export ports.\n",
      "\n",
      "  Top Opinions:\n",
      "    1. The US says it is fighting drugs smuggling, but Venezuela says Donald Trump's aim is to topple President Nicol√°s Maduro.\n",
      "    2. The break-in was \"a real blow\", says  L'Escargot Des Grands Crus, which was preparing deliveries for the holiday season.\n",
      "\n",
      "üîç FACT CHECK RESULTS:\n",
      "\n",
      "  Claim: The death toll on the island of Sumatra has risen to more than 440, the government says.\n",
      "  Status: CONTRADICTED\n",
      "  Confidence: 0.50\n",
      "  Sources: https://ca.news.yahoo.com/indonesia-searches-hundreds-missing-deadly-161712489.html\n",
      "\n",
      "  Claim: At least 80 people have died in Indonesia with another 56 dead in Sri Lanka in a week of extreme weather.\n",
      "  Status: SUPPORTED\n",
      "  Confidence: 0.50\n",
      "  Sources: https://www.weatherapi.com/\n",
      "\n",
      "  Claim: Dozens have been arrested during climate protests at one of the world's biggest coal export ports.\n",
      "  Status: SUPPORTED\n",
      "  Confidence: 0.50\n",
      "  Sources: https://www.tiktok.com/@bbcnews/video/7578535955653610774\n",
      "\n",
      "  Claim: Police say 10 others are injured in what they believe is a \"targeted\" shooting, with children among the victims.\n",
      "  Status: SUPPORTED\n",
      "  Confidence: 0.50\n",
      "  Sources: https://www.facebook.com/LovinMalta/videos/at-least-four-people-have-been-killed-and-ten-others-injured-after-a-mass-shooti/1053127786897206/\n",
      "\n",
      "  Claim: A state of emergency is announced as Sri Lanka grapples with its worst weather disaster in years.\n",
      "  Status: SUPPORTED\n",
      "  Confidence: 0.50\n",
      "  Sources: https://www.weatherapi.com/\n",
      "\n",
      "üí¨ LANGUAGE ANALYSIS:\n",
      "  Tone: neutral\n",
      "  Language Bias Score: 0.20\n",
      "  Loaded Phrases: 3\n",
      "    Examples: targeted shooting, real blow, worst weather disaster in years\n",
      "\n",
      "‚öñÔ∏è  FINAL BIAS ASSESSMENT:\n",
      "  Bias Score: 0.30 / 1.0\n",
      "  Stance: neutral\n",
      "  Confidence: 0.70\n",
      "\n",
      "  Key Factors:\n",
      "    ‚Ä¢ neutral tone\n",
      "    ‚Ä¢ contradicted fact\n",
      "    ‚Ä¢ loaded phrases\n",
      "\n",
      "  üí° Recommendation:\n",
      "  Readers should consider multiple sources to get a comprehensive view of the events\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Analyze article from URL (this will demonstrate the breakpoint)\n",
    "\n",
    "# Replace with an actual news article URL\n",
    "example_url = \"https://www.bbc.com/news/world\"  # Replace with actual article URL\n",
    "\n",
    "# Run analysis - will pause at review node if needed\n",
    "result = analyze_news(article_url=example_url, thread_id=\"example2\")\n",
    "\n",
    "# If paused, you can inspect the result here, then continue:\n",
    "# result = continue_analysis(thread_id=\"example2\", approved=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee7b357a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∞ News Bias Detector - Interactive Mode\n",
      "================================================================================\n",
      "üì• Fetching article from: https://thewire.in/history/past-continuous-1993-bombay-blasts-were-in-response-an-entire-community-being-alienated\n",
      "‚úì Fetched 208 characters\n",
      "\n",
      "üöÄ Starting bias detection analysis...\n",
      "================================================================================\n",
      "\n",
      "üîÑ Running: Summarization Node\n",
      "‚úì Summary: The 1993 Bombay blasts were part of a larger continuum of terror, according to an article by The Wir...\n",
      "\n",
      "üîÑ Running: Claims Extraction Node\n",
      "‚úì Extracted 2 factual claims\n",
      "‚úì Extracted 1 opinions\n",
      "\n",
      "üîÑ Running: Fact Checking Node\n",
      "  üîç Checking: 1993 Bombay Blasts...\n",
      "    ‚úì Status: supported (confidence: 0.50)\n",
      "  üîç Checking: The Wire News India, Latest News,News from India, Politics, ...\n",
      "    ‚úì Status: supported (confidence: 0.50)\n",
      "\n",
      "üîÑ Running: Language Analysis Node\n",
      "‚úì Tone: negative\n",
      "‚úì Language bias score: 0.60\n",
      "‚úì Found 2 loaded phrases\n",
      "\n",
      "üîÑ Running: Bias Scoring Node\n",
      "‚úì Bias score: 0.60\n",
      "‚úì Stance: left-leaning\n",
      "‚úì Confidence: 0.70\n",
      "\n",
      "================================================================================\n",
      "üì∞ NEWS BIAS DETECTION REPORT\n",
      "================================================================================\n",
      "\n",
      "üîó Source URL: https://thewire.in/history/past-continuous-1993-bombay-blasts-were-in-response-an-entire-community-being-alienated\n",
      "\n",
      "üìù SUMMARY:\n",
      "The 1993 Bombay blasts were part of a larger continuum of terror, according to an article by The Wire. The article discusses the blasts as a significant event in India's history of terrorism. The article provides context and information about the blasts and their place in the broader narrative of terror in India.\n",
      "Word count: ~300\n",
      "\n",
      "üìä CLAIMS EXTRACTED:\n",
      "  Factual claims: 2\n",
      "  Opinions: 1\n",
      "\n",
      "  Top Factual Claims:\n",
      "    1. 1993 Bombay Blasts\n",
      "    2. The Wire News India, Latest News,News from India, Politics, External Affairs, Science, Economics, Gender and Culture\n",
      "\n",
      "  Top Opinions:\n",
      "    1. Part of a Continuum of Terror\n",
      "\n",
      "üîç FACT CHECK RESULTS:\n",
      "\n",
      "  Claim: 1993 Bombay Blasts\n",
      "  Status: SUPPORTED\n",
      "  Confidence: 0.50\n",
      "  Sources: https://www.youtube.com/watch?v=KhSFC1GNgNM\n",
      "\n",
      "  Claim: The Wire News India, Latest News,News from India, Politics, External Affairs, Science, Economics, Gender and Culture\n",
      "  Status: SUPPORTED\n",
      "  Confidence: 0.50\n",
      "  Sources: https://m.thewire.in/amp\n",
      "\n",
      "üí¨ LANGUAGE ANALYSIS:\n",
      "  Tone: negative\n",
      "  Language Bias Score: 0.60\n",
      "  Loaded Phrases: 2\n",
      "    Examples: Continuum of Terror, Part of a Continuum\n",
      "\n",
      "‚öñÔ∏è  FINAL BIAS ASSESSMENT:\n",
      "  Bias Score: 0.60 / 1.0\n",
      "  Stance: left-leaning\n",
      "  Confidence: 0.70\n",
      "\n",
      "  Key Factors:\n",
      "    ‚Ä¢ negative tone\n",
      "    ‚Ä¢ loaded phrases\n",
      "    ‚Ä¢ one-sided coverage\n",
      "\n",
      "  üí° Recommendation:\n",
      "  Readers should consider multiple sources for a balanced view\n",
      "\n",
      "================================================================================\n",
      "‚úì Interactive mode ready - uncomment last line to run\n"
     ]
    }
   ],
   "source": [
    "# Interactive cell for testing with any URL\n",
    "\n",
    "def interactive_analysis():\n",
    "    \"\"\"\n",
    "    Interactive function to analyze news from URL input.\n",
    "    \"\"\"\n",
    "    print(\"üì∞ News Bias Detector - Interactive Mode\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Get URL input\n",
    "    url = input(\"\\nEnter news article URL (or 'quit' to exit): \").strip()\n",
    "    \n",
    "    if url.lower() == 'quit':\n",
    "        print(\"Exiting...\")\n",
    "        return\n",
    "    \n",
    "    if not url:\n",
    "        print(\"‚ùå No URL provided\")\n",
    "        return\n",
    "    \n",
    "    # Analyze\n",
    "    result = analyze_news(article_url=url, thread_id=\"interactive\")\n",
    "    \n",
    "    # If paused for review\n",
    "    if result and result.get('needs_human_review') and not result.get('human_approved'):\n",
    "        approve = input(\"\\n‚ùì Approve and continue? (yes/no): \").strip().lower()\n",
    "        if approve == 'yes':\n",
    "            result = continue_analysis(thread_id=\"interactive\", approved=True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run interactive mode\n",
    "interactive_analysis()\n",
    "\n",
    "print(\"‚úì Interactive mode ready - uncomment last line to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eb895f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Results exported to my_analysis.json\n",
      "‚úì Export function defined\n"
     ]
    }
   ],
   "source": [
    "def export_results(state: BiasDetectorState, filename: str = \"bias_report.json\"):\n",
    "    \"\"\"\n",
    "    Export analysis results to JSON file.\n",
    "    \"\"\"\n",
    "    output = {\n",
    "        \"article_url\": state.get('article_url'),\n",
    "        \"summary\": {\n",
    "            \"text\": state['summary'].summary if state.get('summary') else None,\n",
    "            \"word_count\": state['summary'].word_count if state.get('summary') else None\n",
    "        },\n",
    "        \"claims\": {\n",
    "            \"factual\": [{\"text\": c.text, \"confidence\": c.confidence} \n",
    "                       for c in state['claims'].factual_claims] if state.get('claims') else [],\n",
    "            \"opinions\": [{\"text\": c.text, \"confidence\": c.confidence} \n",
    "                        for c in state['claims'].opinions] if state.get('claims') else []\n",
    "        },\n",
    "        \"fact_checks\": [\n",
    "            {\n",
    "                \"claim\": fc.claim,\n",
    "                \"status\": fc.status,\n",
    "                \"confidence\": fc.confidence,\n",
    "                \"sources\": fc.sources\n",
    "            } for fc in state['fact_checks'].checks\n",
    "        ] if state.get('fact_checks') else [],\n",
    "        \"language_analysis\": {\n",
    "            \"tone\": state['language_analysis'].tone if state.get('language_analysis') else None,\n",
    "            \"bias_score\": state['language_analysis'].language_bias_score if state.get('language_analysis') else None,\n",
    "            \"loaded_phrases\": state['language_analysis'].loaded_phrases if state.get('language_analysis') else []\n",
    "        },\n",
    "        \"bias_report\": {\n",
    "            \"bias_score\": state['bias_report'].bias_score if state.get('bias_report') else None,\n",
    "            \"stance\": state['bias_report'].stance if state.get('bias_report') else None,\n",
    "            \"confidence\": state['bias_report'].confidence if state.get('bias_report') else None,\n",
    "            \"key_factors\": state['bias_report'].key_factors if state.get('bias_report') else [],\n",
    "            \"recommendation\": state['bias_report'].recommendation if state.get('bias_report') else None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"‚úì Results exported to {filename}\")\n",
    "\n",
    "export_results(result, \"my_analysis.json\")\n",
    "\n",
    "print(\"‚úì Export function defined\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
